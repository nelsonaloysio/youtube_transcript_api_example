{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c70c8f6a",
   "metadata": {},
   "source": [
    "# Download YouTube video transcripts\n",
    "\n",
    "Let's define a `YouTubeWrapper` class containing some functions and [static methods](https://docs.python.org/pt-br/3/library/functions.html?highlight=staticmethod#staticmethod) (`@staticmethod`):\n",
    "\n",
    "> * `get_subtitles`: download one or multiple transcripts from YouTube videos\n",
    "\n",
    "> * `get_video_ids`: read file containing video IDs (one per line)\n",
    "\n",
    "> * `get_subtitle`: convert transcript to subtitle (`.srt` format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ded09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "class YouTubeWrapper():\n",
    "    \"\"\"\n",
    "    Get transcripts using youtube_transcript_api.\n",
    "    \"\"\"\n",
    "    def get_transcripts(self, video_ids, languages=[\"pt\", \"pt-BR\", \"en\", \"en-US\"]):\n",
    "        transcripts = {}\n",
    "        \n",
    "        if type(video_ids) == str:\n",
    "            video_ids = video_ids.split(\",\")\n",
    "        \n",
    "        for video_id in video_ids:\n",
    "            try:\n",
    "                transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=languages)\n",
    "            except:\n",
    "                print(f\"Error for video: https://www.youtube.com/watch?v={video_id}.\")\n",
    "            else:\n",
    "                df = pd.DataFrame(transcript)\n",
    "                df.to_csv(f\"transcripts/transcript_{video_id}.csv\", index=False)\n",
    "\n",
    "                with open(f\"transcripts/subtitle_{video_id}.srt\", \"w\") as f:\n",
    "                    f.write(self.get_subtitle(df))\n",
    "\n",
    "                transcripts[video_id] = df\n",
    "        \n",
    "        print(f\"Got {len(transcripts)} subtitles.\")\n",
    "        return transcripts\n",
    "\n",
    "    @staticmethod\n",
    "    def get_video_ids(file_name, header=True):\n",
    "        with open(file_name, \"r\") as f:\n",
    "            video_ids = [\n",
    "                line.split(\"/\")[-1].strip()\n",
    "                for i, line in enumerate(f.readlines())\n",
    "                if (i > 0 or header is False)\n",
    "            ]\n",
    "        print(\"Read %s lines.\" % len(video_ids))\n",
    "        return video_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def get_subtitle(df: pd.DataFrame):\n",
    "    \n",
    "        def get_time(s: str):\n",
    "            seconds = str(timedelta(seconds=s))\n",
    "            return f\"{seconds[:7]},{seconds[8:11]}\"\n",
    "\n",
    "        srt = \"\"\n",
    "        \n",
    "        df[\"end\"] = df[\"start\"] + df[\"duration\"]\n",
    "        df[\"start_time\"] = df[\"start\"].apply(get_time)\n",
    "        df[\"end_time\"] = df[\"end\"].apply(get_time)\n",
    "\n",
    "        count = 1\n",
    "        for row in range(df.shape[0]):\n",
    "            srt += f\"{count}\\n{df.loc[row]['start_time']} --> {df.loc[row]['end_time']}\\n{df.loc[row]['text']}\\n\\n\"\n",
    "            count += 1\n",
    "\n",
    "        return srt\n",
    "    \n",
    "yt = YouTubeWrapper()\n",
    "\n",
    "if not os.path.isdir(\"transcripts\"):\n",
    "    os.mkdir(\"transcripts\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0305e4c2",
   "metadata": {},
   "source": [
    "### Set video IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [\"dSu5sXmsur4\", \"BmX86O2ozdo\", \"Bpfw47x5a90\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64b72462",
   "metadata": {},
   "source": [
    "##### Alternative: read video IDs from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad27c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_ids = yt.get_video_ids(\"video_ids.txt\", header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8695661f",
   "metadata": {},
   "source": [
    "### Download video transcripts and save to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdfd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = yt.get_transcripts(video_ids) # languages=[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "610a0f64",
   "metadata": {},
   "source": [
    "### Extra stuff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a387fda",
   "metadata": {},
   "source": [
    "#### List available transcript languages for a YouTube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_id in video_ids:\n",
    "    languages = [\"pt\", \"pt-BR\", \"en\", \"en-US\"]\n",
    "    \n",
    "    try:\n",
    "        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "        manual = transcript_list.find_manually_created_transcript(languages)\n",
    "        automatic = transcript_list.find_generated_transcript(languages)\n",
    "\n",
    "        print(f\"[{video_id}]\\n- Subtitles added manually: {manual}\\n- Subtitles added automatically: {automatic}\\n\")\n",
    "    except:\n",
    "        print(f\"[{video_id}]\\n- No subtitles available in the selected languages.\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf4917b2",
   "metadata": {},
   "source": [
    "#### Transform all transcripts to a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ad4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(transcripts.values()); df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7df4c901",
   "metadata": {},
   "source": [
    "#### Plot most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = 4\n",
    "\n",
    "df[\"text\"] \\\n",
    ".apply(\n",
    "    lambda x: [word.strip(punctuation) for word in x.lower().replace(\"\\n\", \" \").split() if len(word) > min_length]\n",
    ") \\\n",
    ".explode() \\\n",
    ".value_counts()[:50] \\\n",
    ".sort_values(ascending=True) \\\n",
    ".plot(kind=\"barh\", figsize=(12,12), title=f\"Most frequent terms (minimum length: {min_length})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f3e86f05d8baddf70cf80e0364559f9b03ed7f30f85373a81ae132884045b90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
